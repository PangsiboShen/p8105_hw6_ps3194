---
title: "p8105_hw6_ps3194"
author: "Pangsibo Shen"
date: "12/5/2020"
output: github_document
---
```{r message=FALSE}
library(tidyverse)
library(modelr)
library(p8105.datasets)
library(broom)
```

## Problem 1

```{r}
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) %>%
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
    ) %>% 
  filter(
    victim_race %in% c("White", "Black"),
    city_state != c("Tulsa, AL")
    ) %>%
  select(city_state, resolution, victim_age, victim_race, victim_sex)

homicide_df %>%
  head() %>%
  knitr::kable()
```

Start with one city Baltimore.

```{r}
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")

glm(resolution ~ victim_age + victim_race + victim_sex,
    data = baltimore_df,
    family = binomial()) %>%
  broom::tidy() %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>%
  select(term, OR, starts_with("CI")) %>%
  knitr::kable(digits = 3)
```

The adjusted odds ratio for solving homicides for white is 2.32 with a Confidence Interval (1.648, 3.268). In other words, keeping all other variables fixed, the odds of non-white victim cases been resolved is 2.32 times the odds of white victims cases and we're 95% confidence that the true aOR falls within 1.648 and 3.268.

```{r}
models_results_df = 
  homicide_df %>%
  nest(data = -city_state) %>%
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>%
  select(city_state, results) %>%
  unnest(results) %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>%
  select(city_state, term, OR, starts_with("CI"))
```


```{r}
models_results_df %>%
  filter(term == "victim_sexMale") %>%
  mutate(city_state = fct_reorder(city_state,OR)) %>%
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```
Albuquerque, NM, Stockton, CA and Fresno, CA have the highest aORs for solving homicides comparing Black victims to white victims among all the cities. These three cities also have the widest ranges for CIs among all the cities. New York City has the lowest aORs for solving homicides comparing Black victims to white victims among all the cities and it's CI doesn't include 1. Hence, we can conclude that in New York City, it is more likely for a white-victim case to be solved comparing to a non-white victim case.

-----------------------------------------

## Problem 2

```{r}
birthweight_df = 
  read_csv("data/birthweight.csv") %>%
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace)
  ) %>%
  relocate(bwt, .after = wtgain)
```
```{r}
# Fit a regression using all predictors
mult_fit = lm(bwt ~., data = birthweight_df)
summary(mult_fit)
```

In order to propose a regression model for birthweight, I am going to implement backward elimination which takes out non-significant variables 'one at a time' starting with the highest p-value until all non-significant predictors have been removed.

```{r}
# backward elimination
step(mult_fit, direction = 'backward')
```

After the backward elimination, we ended up with a new model below:

$$
bwt = \beta_0+\beta_1babysex+\beta_2bhead+\beta_3blength+\beta_4delwt+\beta_5fincome+\beta_6gaweeks+\beta_7mheight+\beta_8mrace + \beta_9parity + \beta_{10}ppwt+ \beta_{11}smoken
$$

```{r}
fit_be = lm(formula = bwt ~ babysex + bhead + blength + delwt + fincome + 
    gaweeks + mheight + mrace + parity + ppwt + smoken, data = birthweight_df)
summary(fit_be)

fit_model =  lm(formula = bwt ~ babysex + bhead  + blength + wtgain + gaweeks + mheight + mrace + parity  + smoken, data = birthweight_df)
summary(fit_model)
```

After reviewed the summary of the model after backward elimination, we took additional step to drop the fincome since its p-value is greater than 0.05. We also removed delwt and ppwt and added wtgain which is delwt - ppwt. Finally, we got the fit_model as the proposed model.

$$
bwt = \beta_0+\beta_1babysex+\beta_2bhead+\beta_3blength+\beta_4wtgain+\beta_5gaweeks+\beta_6mheight+\beta_7mrace + \beta_8parity + \beta_9smoken
$$

```{r}
# Diagnostics
birthweight_df %>% 
  modelr::add_residuals(fit_model) %>% 
  modelr::add_predictions(fit_model) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() +
  xlab("Predicted/Fitted value") +
  ylab("Residual") +
  ggtitle("Residual vs Fitted Values Plot for Proposed Model") +
  geom_hline(yintercept=00, linetype = "dashed", color = "red")
```

Now let's construct the other two models provided by the prompt!

```{r}
fit_p1 = lm(formula = bwt ~ blength + gaweeks, data = birthweight_df)
tidy(fit_p1)
fit_p2 = lm(formula = bwt ~ babysex*bhead*blength, data = birthweight_df)
tidy(fit_p2)
```

```{r}
cv_df = 
  crossv_mc(birthweight_df, 100) %>%
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )
```

```{r}
cv_df = 
  cv_df %>% 
  mutate(
    fit_model = map(.x = train, ~ lm(formula = bwt ~ babysex + bhead  + blength + wtgain + gaweeks + mheight + mrace + parity  + smoken, data = .x)),
    fit_p1 = map(.x = train, ~ lm(formula = bwt ~ blength + gaweeks, data = .x)),
    fit_p2 = map(.x = train, ~ lm(formula = bwt ~ babysex*bhead*blength, data = .x))
  ) %>% 
  mutate(
    rmse_proposed = map2_dbl(.x = fit_model, .y = test, ~rmse(model = .x, data = .y)),
    rmse_p1 = map2_dbl(.x = fit_p1, .y = test, ~rmse(model = .x, data = .y)),
    rmse_p2 = map2_dbl(.x = fit_p2, .y = test, ~rmse(model = .x, data = .y))
  )
```

```{r}
#calculate mean prediction error across three models
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  group_by(model) %>% 
  summarize(avg_rmse = mean(rmse))
```

```{r}
#plot the mean prediction error density across three models
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin()
```
My proposed model using backward elimination has the smallest average rmse of 274.9 among three models. Model p1 which is using length at birth and gestational age as predictors has the largest average rmse of 335.4.

-----------------------------------------

## Porblem 3
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r}
set.seed(123)
#create bootstrap object with 5000 estimates
weather_bootstrap = 
  weather_df %>%
  modelr::bootstrap(5000, id = "strap_number") %>%
  mutate(
    models = map(.x = strap, ~lm(tmax ~tmin, data = .x)), 
    results = map(models, broom::tidy),
    glance = map(models, broom::glance)
  ) %>%
  select(strap_number, results, glance)
```

```{r}
#Plot the distribution of r squared
weather_bootstrap %>%
  unnest(glance) %>%
  ggplot(aes(r.squared)) +
  geom_density() +
  ggtitle("The Distribution of R Squared")

r_squared = 
  weather_bootstrap %>%
  unnest(glance) %>%
  select(r.squared) %>%
  unlist()

#construct 95% CI for r squared
r_squared_CI = 
  tibble(
    mean = mean(r_squared),
    ci_lower = quantile(r_squared, 0.025),
    ci_upper = quantile(r_squared, 0.975)
    )

r_squared_CI
```
The estimate for R square is 0.9116109 with confidence interval lower bound of 0.8943557 and upper bound 0.9273405.The distribution for R squared is a little skewed to the left and doesn't quite follow a normal distribution. But since we are using bootstrap, we don't have to worry about distribution assumption to make inference.


```{r}
#Plot the distribution of log(intercept*beta1)
weather_bootstrap %>%
  unnest(results) %>%
  select(strap_number, term, estimate) %>%
  pivot_wider(names_from  = term, values_from = estimate) %>%
  rename(intercept = '(Intercept)') %>%
  mutate(estimate = log10(intercept*tmin)) %>%
  ggplot(aes(estimate)) +
  geom_density() +
  ggtitle("The Distribution of log(intercept*beta1)")

log_betas = 
  weather_bootstrap %>%
  unnest(results) %>%
  select(strap_number, term, estimate) %>%
  pivot_wider(names_from  = term, values_from = estimate) %>%
  rename(intercept = '(Intercept)') %>%
  mutate(estimate = log10(intercept*tmin)) %>%
  select(estimate) %>%
  unlist()

#construct 95% CI for log(intercept*beta1)
log_betas_CI = 
  tibble(
    mean = mean(log_betas),
    ci_lower = quantile(log_betas, 0.025),
    ci_upper = quantile(log_betas, 0.975)
    )

log_betas_CI
```
The estimate for $log(\hat\beta_0*\hat\beta_1)$ is 0.8744846 with confidence interval lower bound of 0.85364 and upper bound 0.8940337. distribution for $log(\hat\beta_0*\hat\beta_1)$ has two peaks in the middle. But since we are using bootstrap, we don't have to worry about distribution assumption to make inference.





